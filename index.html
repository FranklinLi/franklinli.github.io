<!DOCTYPE HTML>
<!--
	Strata by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Franklin Mingzhe Li</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<div class="inner">
					<a href="#" class="image avatar"><img src="franklin-profile.jpg" alt="" /></a>
					<h1><strong>FRANKLIN MINGZHE LI</strong></strong>
					</h1>
					<h1>407 S. Craig Street, Room 212<br />Pittsburgh, PA 15213<br />
					</h1>
					<h1>mingzhe2[at]andrew[dot]cmu[dot]edu<br /> 
					</h1>
					<h1><strong><a href="Franklin_Mingzhe_Li_Resume (5).pdf"> [CV]</a></strong> <strong><a href="https://scholar.google.com/citations?user=jZa4SPIAAAAJ&hl=en">[Google Scholar] </a></strong>
					</h1>
				
				
				</div>
			</header>

		<!-- Main -->
			<div id="main">

				<!-- One -->
					<section id="one">
						<header class="major">
							<h2>HCI, Accessibility, and Ubicomp <br />
							</h2>
						</header>
						<p>Franklin Mingzhe Li is a <a href="https://www.nserc-crsng.gc.ca/students-etudiants/pg-cs/bellandpostgrad-belletsuperieures_eng.asp">NSERC Postgraduate Fellow</a> and a PhD student supervised by <a href="https://www.patrickcarrington.com/">Prof. Patrick A. Carrington</a> in the Human-Computer Interaction Institute at Carnegie Mellon University. He obtained Master of Science degree supervised by <a href="https://www.cs.toronto.edu/~khai/">Prof. Khai N. Truong</a> in the Department of Computer Science at the University of Toronto. His research interests are in Human-Computer Interaction (HCI), Assistive Technology, and Ubiquitous Computing (UbiComp). His research focused on exploring, designing, and deploying Assistive Technologies for physical space and Activities of Daily Living for people with disabilities. His dissertation focused on supporting and enabling non-visual cooking for people with vision impairments through AI and Assistive Technologies.<br /></p>
                    
					</section>

				<!-- One -->
					<section id="one">
						<header class="major">
							<h2>Recent News<br />
							</h2>
						</header>
						<p>
						Jun 2024, Traveling to HCIC 2024 (Wisconsin, USA)!<br />
						May 2024, Traveling to CHI 2024 (Hawaii, USA)!<br />
						Jan 2024, Four papers accepted to CHI 2024!<br />
						Oct 2023, Invited Talk at University of Notre Dame (Topic: Building Usable Systems for People with Disabilities in Physical Activities
)<br />
						Oct 2023, Traveling to Ubicomp 2023 (Cancun, Mexico)<br />
						Jul 2023, One paper and one poster got accepted to ASSETS 2023!<br />
						Apr 2023, Traveling to CHI 2023 (Hamburg, Germany)<br />
						Mar 2023, Invited Talk at APEX Lab, HKUST (Topic: Leveraging AI for Accessibility in Physical Space)<br />
						Feb 2023, Invited Talk at DGP, University of Toronto (Topic: Leveraging AI for Accessibility in Physical Space)<br />
						Feb 2023, Two papers accepted to CHI 2023!<br />
						Nov 2022, Traveling to ASSETS 2022 (Athens, Greece)<br />
						Aug 2022, Google's Research Collabs got accepted!<br />
						Jul 2022, one paper accepted to ASSETS 2022!<br />
						</p>
						
					</section>
				
				
                    <!-- One -->
                    <section id="one">
                        <header class="major">
                            <h2>Selected Peer-Reviewed Full Conference or Journal Publications<br />
                            </h2>
						</header>
						<p><img src = "chi24-343-fig2.jpg" alt=""/ height="140" ><br /><strong>A Contextual Inquiry of People with Vision Impairments in Cooking
<br />Franklin Mingzhe Li</strong>, Michael Xieyang Liu, Shaun K Kane, Patrick Carrington<br /> <strong>In Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI), 2024</strong> <a href="Contextual Inquiry Cooking 1.pdf"> [PDF]</a></p>
			    			<p><img src = "chi24-977-fig6.jpg" alt=""/ height="140" ><br /><strong>Co-design Accessible Public Robots: Insights from People with Mobility Disability, Robotic Practitioners and Their Collaborations<br /></strong>Howard Ziyu Han, <strong>Franklin Mingzhe Li</strong>, Alesandra Baca Vazquez, Daragh Byrne, Nikolas Martelaro, Sarah E Fox<br /> <strong>In Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI), 2024</strong> <a href="Accessible Robot.pdf"> [PDF]</a></p>
			    			<p><img src = "chi24-986-fig5.jpg" alt=""/ height="140" ><br /><strong>Designing Upper-Body Gesture Interaction with and for People with Spinal Muscular Atrophy in VR
<br /></strong>Jingze Tian, Yingna Wang, Keye Yu, Liyi Xu, Junan Xie, <strong>Franklin Mingzhe Li</strong>, Yafeng Niu, Mingming Fan<br /> <strong>In Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI), 2024</strong> <a href="Gesture VR.pdf"> [PDF]</a></p>
			    			<p><img src = "chi24-260-fig2.jpg" alt=""/ height="140" ><br /><strong>Selenite: Scaffolding Online Sensemaking with Comprehensive Overviews Elicited from Large Language Models<br /></strong>Michael Xieyang Liu, Tongshuang Wu, Tianying Chen, <strong>Franklin Mingzhe Li</strong>, Aniket Kittur, Brad A Myers<br /><strong>In Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI), 2024</strong> <a href="Selenite.pdf"> [PDF]</a></p>
						<p><img src = "images/embedded.png" alt=""/ height="140" ><br /><strong>Embodied Exploration: Facilitating Remote Accessibility Assessment for Wheelchair Users with Virtual Reality <br /></strong>Siyou Pei, Alexander Chen, Chen Chen, <strong>Franklin Mingzhe Li</strong>, Megan Fozzard, Hao-Yun Chi, Nadir Weibel, Patrick Carrington, Yang Zhang<br /> <strong>In Proceedings of the 25th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS), 2023</strong> <a href="embedded.pdf"> [PDF]</a></p>
			    			<p><img src = "chi23-260.png" alt=""/ height="140" ><br /><strong>Understanding Visual Arts Experiences of Blind People
<br />Franklin Mingzhe Li*</strong>, Lotus Zhang*, Maryam Bandukda, Abigale Stangl, Kristen Shinohara, Leah Findlater, Patrick Carrington (*Equal contribution)<br /> <strong>In Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI), 2023</strong> <a href="chi23-260.pdf"> [PDF]</a></p>
			    
			    			<p><img src = "upper_extremity_health.png" alt=""/ height="140" ><br /><strong>Breaking the "Inescapable" Cycle of Pain: Supporting Wheelchair Users' Upper Extremity Health Awareness and Management with Tracking Technologies
<br /></strong> Yunzhi Li, <strong>Franklin Mingzhe Li</strong>, Patrick Carrington<br /> <strong>In Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI), 2023</strong> <a href="upper_extremity_health.pdf"> [PDF]</a></p>
			    
			    			<p><img src = "images/multimodal.png" alt=""/ height="140" ><br /><strong>Freedom to Choose: Understanding Input Modality Preferences of People with Upper-body Motor Impairments for Activities of Daily Living <br />Franklin Mingzhe Li</strong>, Michael Xieyang Liu, Yang Zhang, Patrick Carrington<br /> <strong>In Proceedings of the 24th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS), 2022 </strong> <a href="multimodal.pdf"> [PDF]</a></p>
			    			<p><img src = "BlindMakeup.png" alt=""/ height="140" ><br /><strong>“It Feels Like Taking a Gamble”: Exploring Perceptions, Practices, and Challenges of Using Makeup and Cosmetics for People with Visual Impairments<br />Franklin Mingzhe Li*</strong>, Francheska Spektor*, Meng Xia*, Mina Huh*, Peter Cederberg, Yuqi Gong, Kristen Shinohara, Patrick Carrington (*Equal contribution)<br /> <strong>In Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI), 2022</strong> <a href="BlindMakeup.pdf"> [PDF]</a></p>
			    			<p><img src = "OlderAdultsVisualization.png" alt=""/ height="140" ><br /><strong>Understanding How Older Adults Comprehend COVID-19 Interactive Visualizations via Think-Aloud Protocol</strong><br />Mingming Fan, Yiwen Wang, Yuni Xie, <strong>Franklin Mingzhe Li</strong>, Chunyang Chen<br /> <strong>International Journal of Human-Computer Interaction (IJHCI), 2022 </strong> <a href="OlderAdultsVisualization.pdf"> [PDF]</a></p>
			    			<p><img src = "images/Craption.jpg" alt=""/ height="140" ><br /><strong>An Exploration of Captioning Practices and Challenges of Individual Content Creators on YouTube for People with Hearing Impairments<br />Franklin Mingzhe Li</strong>, Cheng Lu, Zhicong Lu, Patrick Carrington, Khai N. Truong<br /> <strong>In Proceedings of ACM on Human-Computer Interaction (PACMHCI), Volume 6, Issue CSCW1, Article 75, 2022</strong> <a href="CSCW22_Craption.pdf"> [PDF]</a></p>
			                        <p><img src = "images/nonvisualcooking.JPG" alt=""/ height="140" ><br /><strong>Non-Visual Cooking: Exploring Practices and Challenges of Meal Preparation by People with Visual Impairments <br />Franklin Mingzhe Li</strong>, Jamie Dorst, Peter Cederberg, Patrick Carrington<br /> <strong>In Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS), 2021 </strong> <a href="2107.05783.pdf"> [PDF]</a></p>
			    			<p><img src = "images/ThumbTrak.png" alt=""/ height="140" ><br /><strong>ThumbTrak: Recognizing Micro-finger Poses Using a Ring with Proximity Sensing</strong><br />Wei Sun, <strong>Franklin Mingzhe Li</strong>, Congshu Huang, Zhenyu Lei, Benjamin Steeper, Songyun Tao, Feng Tian, Cheng Zhang<br /> <strong>In Proceedings of the 23rd International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI), 2021 </strong><a href="ThumbTrak_MobileHCI'21.pdf"> [PDF]</a></p>
			    			<p><img src = "images/Misperception.png" alt=""/ height="140" ><br /><strong>"I Choose Assistive Devices That Save My Face" A Study on Perceptions of Accessibility and Assistive Technology Use Conducted in China</strong><br /><strong>Franklin Mingzhe Li</strong>, Di Laura Chen, Mingming Fan, Khai N. Truong<br /> <strong>In Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI), 2021 </strong><a href="ChineseATs.pdf"> [PDF]</a></p>
			    			<p><img src = "images/TeethTap.JPG" alt=""/ height="140" ><br /><strong>TeethTap: Recognizing Discrete Teeth Gestures using Motion and Acoustic Sensing on an Earpiece </strong><br />Wei Sun*, <strong>Franklin Mingzhe Li*</strong>, Benjamin Steeper*, Songlin Xu, Feng Tian, Cheng Zhang (*Equal contribution)<br /> <strong>In Proceedings of the 26th International Conference on Intelligent User Interfaces (IUI), 2021 </strong><a href="iui21a-sub1165-i6 (2).pdf"> [PDF]</a></p>
			    			<p><img src = "images/Assets20-Eyelid.JPG" alt=""/ height="140" ><br /><strong>Eyelid Gestures on Mobile Devices for People with Motor Impairments </strong><br />Mingming Fan*, Zhen Li*, <strong>Franklin Mingzhe Li*</strong> (*Equal contribution)<br /> <strong>In Proceedings of the 22th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS), 2020 </strong><a href="assets20a-sub1243-cam-i26.pdf"> [PDF]</a> <font color="red"> Best Artifact Award </font></p>
						<p><img src = "images/FMT.png" alt=""/ height="140" ><br /><strong>FMT: A Wearable Camera-Based Object Tracking Memory Aid for Older Adults <br />Franklin Mingzhe Li</strong>, Di Laura Chen, Mingming Fan, Khai N. Truong <br /> <strong>In Proceedings of ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT), 2019 </strong> <a href="FMT-IMWUT-19-CameraReady-FinalVersion-V2.pdf"> [PDF]</a></p>
						<p><img src = "images/Face Recognition.png" alt=""/ height="140" ><br /><strong>Face Recognition Assistant for People with Visual Impairments </strong><br />Mohammad Kianpisheh, <strong>Franklin Mingzhe Li</strong>, Khai N. Truong <br /> <strong>In Proceedings of ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT), 2019 </strong> <a href="imwut18c-sub2624-cam-i26 (2).pdf"> [PDF]</a></p>
                        <p><img src = "images/BrailleSketch2.png" alt=""/ height="140" ><br /><strong>BrailleSketch: A Gesture-based Text Input Method for People with Visual Impairments <br />Franklin Mingzhe Li</strong>, Mingming Fan, Khai N. Truong <br /> <strong>In Proceedings of the 19th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS), 2017 </strong> <a href="braillesketch.pdf"> [PDF]</a></p>
                        <p><img src = "images/Haunted.png" alt=""/ height="140" ><br /><strong>The Living Room: Exploring the Haunted and Paranormal to Transform Design and Interaction </strong><br /> Michelle Annett, Matthew Lakier, <strong>Franklin Mingzhe Li</strong>, Daniel Wigdor, Tovi Grossman, George Fitzmaurice <br /> <strong>In Proceedings of the 2016 ACM Conference on Designing Interactive Systems (DIS), 2016 </strong><a href="thelivingroom.pdf"> [PDF]</a></p>
							</section>
					
					<section id="one">
                        <header class="major">
                            <h2>Professional Experiences<br />
                            </h2>
						</header>
						<p><strong>2019.05 - 2019.09<br /></strong>Research Intern at Apple (Turi). Mentored by Dr. Jeffrey P. Bigham, and Dr. Xiaoyi Zhang <br />
						<strong>2016.05 - 2017.08<br /></strong>Hardware Engineer at AMD<br /></p>
					</section>

					<section id="one">
                        <header class="major">
                            <h2>Awards, Grants and Fellowships<br />
                            </h2>
						</header>
						<p>
						 <strong>Graduate Student Assembly/Provost Conference Funds</Strong>, Carnegie Mellon University ($750), Oct 2022<br />
						 <strong>Google's Research Collabs (with Dr. Patrick Carrington and Dr. Shaun Kane)</Strong>, Google Inc. ($80,000 Plus $20,000 in Google Cloud), Aug 2022<br />
						 <strong>Graduate Student Assembly/Provost Conference Funds</Strong>, Carnegie Mellon University ($750), Mar 2022<br />
						 <strong>Postgraduate Scholarship-Doctoral</strong>, Natural Sciences and Engineering Research Council of Canada (NSERC) ($63,000 over 36 Months), April 2021<br />
						 <strong>Inclusive Design Challenge Award (Co-applicant)</strong>, US Department of Transportation ($300,000), Jan 2021<br />
						 <strong>Best Artifact Award</strong>, ASSETS 2020 ($500), Oct 2020<br />
						 <strong>Faculty of Arts And Science Tuition Fellowship</strong>, University of Toronto ($18,558), Sept 2018<br />
						 <strong>Faculty of Arts And Science Program-Level Fellowship</strong>, University of Toronto ($1000), Nov 2018<br />
						 <strong>Markham Intern of the Year Award Nominee</strong>, AMD, Aug 2017<br />
						 <strong>UTRECS Scholarship</strong>, University of Toronto ($6000), Aug 2015</p>
					</section>				
				
					<section id="one">
                        <header class="major">
                            <h2>Patent, Coverage and Featuring<br />
                            </h2>
						</header>
						<p>
					        <strong><a href="https://magazine.cs.cmu.edu/accessibility-enables-equality">The Magazine of CMU's School of Computer Science: </a></strong> Accessibility Enables Equality (2022.07)<br />
						<strong><a href="https://dl.acm.org/doi/abs/10.1145/3498367">Communications of the ACM: </a></strong> Eyelid gestures for people with motor impairments (2022.01)<br />
						<strong><a href="https://patents.google.com/patent/US11106280B1/en">US Patent: </a></strong>On-the-fly calibration for improved on-device eye tracking (2021.08)<br />
						<strong><a href="https://spectrum.ieee.org/tech-talk/biomedical/bionics/the-next-frontier-for-gesture-control-is-teeth">IEEE Spectrum: </a></strong> The Next Frontier for Gesture Control is Teeth (2021.05)<br />
						<strong><a href="https://mobility21.cmu.edu/whats_happening/mobility21-researchers-win-us-department-of-transportation-inclusive-design-challenge-awards/">Mobility21: </a></strong> Mobility21 Researchers Win US Department of Transportation Inclusive Design Challenge Award (2021.01)<br />
						<strong><a href="https://www.newscientist.com/article/2218025-where-have-i-left-my-wallet-this-smart-camera-can-remind-you/">New Scientist: </a></strong> Where have I left my wallet? This smart camera can remind you (2019.09)<br /></p>

					</section>
					
					<section id="one">
                        <header class="major">
                            <h2>Community Services<br />
                            </h2>
						</header>
						<p><strong>SIGCHI Executive Committee</strong><br />Member of Accessibility Committee (2023)</p>
						<p><strong>Organizing Committee</strong><br />Publication Chair (CHI 2025), Accessibility Chair (CHI 2024, CSCW 2023, HCOMP/CI 2023, C&C 2023, C&C 2022, C&C 2021), Inclusion and Broad Participation Chair (Ubicomp 2024), Student Volunteer Co-chair (ASSETS 2022)</p>
						<p><strong>Program Committee</strong><br />Associate Chair (CHI 2025, ASSETS 2024, CHI 2024, Chinese-CHI 2021, CHI 2020 Late Breaking Works)</p>
						<p><strong>Reviewers</strong><br />ASSETS 2024 (7), UIST 2024 (2), IMWUT 2024 (2) CHI 2024 (13), ASSETS 2023 (2), CHI 2023 (5), TACCESS 2023 (1), IMWUT 2023 (1), UIST 2023 (1), TACCESS 2022 (1), ISS 2022 (2), CHI 2022 (7), CHI 2022 Late Breaking Works (1), ISS 2021 (1), UIST 2021 (1), CSCW 2021 (3), CHI 2021 (4), Chinese-CHI 2021(3), IDC 2021 (1), EICS PACM 2021 (1), UIST 2020 (1), IJHCS (1), CHI 2020 (2), CHI 2020 Late Breaking Works (8), CHI 2019 Late Breaking Works (5)</p>
						<p><strong>Student Volunteer</strong><br />ASSETS 2020</p>
					</section>
			<header class="major">
				<h2>Teaching Experiences and Invited Talks<br />
                            </h2>
						</header>
						<p><strong>Invited Talk: Building Usable Systems for People with Disabilities in Physical Activities</strong><br />University of Rochester (Mar 2024), Invited by Dr. Yukang Yan<br />
						<strong>Guest Lecture: Designing Human-Centered Software</strong><br />Carnegie Mellon University (Mar 2024), Invited by Dr. Aaron Steinfeld<br />
						<strong>Guest Lecture: Designing Human-Centered Software</strong><br />Carnegie Mellon University (Feb 2024), Invited by Dr. Sherry Tongshuang Wu<br />
						<strong>Invited Talk: Building Usable Systems for People with Disabilities in Physical Activities</strong><br />University of Notre Dame (Oct 2023), Invited by Dr. Toby Jia-jun Li<br />
						<strong>Guest Lecture: Designing Human-Centered Software</strong><br />Carnegie Mellon University (Oct 2023), Invited by Dr. Aaron Steinfeld and Dr. Sherry Tongshuang Wu<br />
						<strong>Teaching Assistant: Designing Human-Centered Software</strong><br />Carnegie Mellon University (May 2023)<br />
						<strong>Invited Talk: Leveraging AI for Accessibility in Physical Space</strong><br />APEX Lab, The Hong Kong University of Science and Technology (HKUST) (Mar 2023), Invited by Dr. Mingming Fan<br />
						<strong>Invited Talk: Leveraging AI for Accessibility in Physical Space</strong><br />DGP Lab, University of Toronto (Feb 2023)<br />
						<strong>Teaching Assistant: User-Centered Research and Evaluation</strong><br />Carnegie Mellon University (Dec 2022)<br />
						<strong>Teaching Assistant: CSC258H1S: Computer Organization</strong><br />University of Toronto (Apr 2019)<br />
						<strong>Teaching Assistant: CSC258H1S: Computer Organization</strong><br />University of Toronto (Dec 2018)</p>

					</section>
			</div>

		<!-- Footer -->
			

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
